'year.p',
'decimalLatitude.p',
'decimalLongitude.p',
'coordinateUncertaintyInMeters.p'))
this_query$fields <- paste(fields, collapse = ",")
qa = as.character(c('zeroCoordinates',
#'nameNotSupplied',
'nameNotRecognised',
'decimalLatLongCalculationFromEastingNorthingFailed',
'zeroLatitude',
#'decimalLatLongCalculationFromVerbatimFailed',
'coordinatesCentreOfCountry',
'processingError',
'occCultivatedEscapee',
'coordinatesCentreOfStateProvince',
'decimalLatLongConversionFailed',
'zeroLongitude'))
qa = 'includeall'
this_query$qa <- paste(qa, collapse = ",")
this_query$reasonTypeId <- download_reason_id
this_query$esc <- "\\"
this_query$sep <- ","
fn = gsub("[[:punct:]]", "_", taxon)
fn = paste(fn, Sys.Date(), sep = '_')
fn = gsub(' ', '_', fn)
this_query$file <- fn
## url builder
build_url_from_parts <- function(base_url,path=NULL,query=list()) {
this_url <- parse_url(base_url)
this_url$path <- clean_path(this_url$path,path)
if (length(query)>0) {
this_url$query <- query
}
build_url(this_url)
}
this_url <- build_url_from_parts(getOption("ALA4R_server_config")$base_url_biocache,
c("occurrences", "offline", "download"), query = this_query)
base__url =
getOption("ALA4R_server_config")$base_url_biocache
getOption("ALA4R_server_config")$base_url_biocache
base__url =
library(ALA4R)
library(ALA4R)
getOption("ALA4R_server_config")$base_url_biocache
method
this_url <- build_url_from_parts(base_url, c("occurrences", "offline", "download"),
query = this_query)
base_url = 'http://biocache.ala.org.au/ws/'
this_url <- build_url_from_parts(base_url, c("occurrences", "offline", "download"),
query = this_query)
??clean_path
clean_path <- function(...,sep="/") {
path1 <- sapply(list(...),FUN=function(z)paste(z,sep=sep,collapse=sep)) ## collapse individual arguments
## workaround to avoid replacing "http://" with "http:/", since this is now used in GUID strings (July 2016)
path <- paste(path1,sep=sep,collapse=sep) ## paste parts together
path <- gsub("http://","http:@@",path,fixed=TRUE)
path <- gsub(paste0("[",sep,"]+"),sep,path) ## remove multiple slashes
path <- gsub("http:@@","http://",path,fixed=TRUE)
sub(paste0("^",sep),"",path) ## remove leading slash
}
this_url <- build_url_from_parts(base_url, c("occurrences", "offline", "download"),
query = this_query)
this_url
result = GET(this_url)
verbose
verbose = TRUE
if(verbose){
if(status_code(result) == 200) {
requestStatus = paste('Request status: ', content(result)$status, sep = '')
queueSize = paste('Queue size: ', content(result)$queueSize, sep = '')
msg = 'ALA query is being processed'
cat(msg, requestStatus, queueSize, sep = '\n')
}
else {
print(paste('Something has gone wrong with the request ',
'(status ', status_code(result), ')', sep = ''))
}
}
requestStatus
content(result)
print(paste('Something has gone wrong with the request ',
'(status ', status_code(result), ')', sep = ''))
if(status_code(result) == 200) {
requestStatus = paste('Request status: ', content(result)$status, sep = '')
queueSize = paste('Queue size: ', content(result)$queueSize, sep = '')
msg = 'ALA query is being processed'
cat(msg, requestStatus, queueSize, sep = '\n')
} else {
msg = paste('Something has gone wrong with the request ',
'(status ', status_code(result), ')', sep = '')
errorType = content(result)$errorType
cat(msg, errorType, sep = '\n')
}
msg = paste(': Something has gone wrong with the request ',
'(status ', status_code(result), ')', sep = '')
errorType = content(result)$errorType
cat(errorType, msg)
cat(errorType, msg, sep = '')
download_occurrences = function (taxon, wkt, fields, qa, method = "offline",
email, download_reason_id, dry_run = FALSE,
verbose = TRUE) {
'Summary'
'-------'
'Simplified and customised ALA occurrence download function'
''
'Args'
'----'
'taxon: any taxonomic search construct'
'wkt: well known text polygon to limit records retrieved'
'fields: CSV of data fields to return. If missing, default used'
'qa: CSV of quality assertion fields to return. If missing default used'
'method: indexed or offline.'
'email: user email'
'download_reason_id: acceptable id (0:12) see ala website'
'verbose: default TRUE'
''
'Returns'
'-------'
'Query status printed to screen'
''
'Depends'
'-------'
'Depends on pkgs: assertthat, httr'
''
'Examples'
'--------'
'download_occurrences(taxon="genus:Wandella", wkt="POLYGON((112.0+44.0,154.0+44.0,154.0+9.0,112.0+9.0,112.0+44.0))", method = "offline",
email="karel.mokany@csiro.au", download_reason_id="7", verbose = TRUE)'
''
'Notes'
'-----'
'Largely a hack of the ALA4R function'
'Strips out many of the capabilities of the original function'
'TODO: add indexed download (currently offline only)'
'end doc string'
pkg_check = suppressWarnings(lapply(c('httr', 'assertthat'), require, character.only = TRUE))
if(!all(unlist(pkg_check))) stop('Could not load one of required packages httr or asserthat')
## possibly leave this in case smaller downloads are required
method <- match.arg(tolower(method), c("offline", "indexed"))
if (method == "indexed") {
valid_fields_type <- "occurrence_stored"
stop('indexed currently not available: use ALA4R package instead')
} else {
valid_fields_type <- "occurrence"
}
is.notempty.string = function(x) {
is.string(x) && !is.na(x) && nchar(x)>0
}
## query container
this_query <- list()
## must be included
if (!missing(taxon)) {
if (is.factor(taxon)) {
taxon <- as.character(taxon)
}
assert_that(is.notempty.string(taxon))
this_query$q <- taxon
}
# optional
if (!missing(wkt)) {
assert_that(is.notempty.string(wkt))
this_query$wkt <- wkt
}
## ammend if I leave out the above
if (length(this_query) == 0) {
stop("invalid request: need at least one of taxon, fq, or wkt to be specified")
}
## leave for now
if (method == "offline") {
#if (record_count_only)
#    stop("record_count_only can only be used with method=\"indexed\"")
if (missing(email) || !is.string(email) || nchar(email) < 1)
stop("email is required for method=offline")
}
## here I think I can just assume that a numeric reason is always entered.
## could even hard-code one.
reason_ok <- !is.na(download_reason_id)
if (reason_ok) {
## Should take a code from 0-12
reason_ok = reason_ok %in% seq(0:12)
}
## modify later
if (!reason_ok) {
stop("download_reason_id must be a valid reason_id. See...")
}
## This guy. I think for our purposes we just need a standard set of
## field names. These could be called from a file, or loaded in the
## function. Assume for now it is loaded into memory and called by
## fields arg.
if (!missing(fields)) {
assert_that(is.character(fields))
this_query$fields <- paste(fields, collapse = ",")
} else {
if(verbose) cat('... Requesting default fields', sep = '\n')
fields = as.character(c('occurrenceID',
'kingdom.p',
'phylum.p',
'classs.p',
'order.p',
'family.p',
'genus.p',
'subgenus.p',
'specificEpithet',
'scientificName.p',
'acceptedNameUsage',
'taxonConceptID.p',
'taxonRank.p',
'eventDate.p',
'year.p',
'decimalLatitude.p',
'decimalLongitude.p',
'coordinateUncertaintyInMeters.p'))
this_query$fields <- paste(fields, collapse = ",")
}
## Think this should error if missing. As above it will probably be a file
## that needs to be in memory (or set to a hard-coded path).
if (!missing(qa)){
assert_that(is.character(qa))
this_query$qa <- paste(qa, collapse = ",")
} else {
if(verbose) cat('... Requesting default quality assertion fields', sep = '\n')
qa = as.character(c('zeroCoordinates',
#'nameNotSupplied',
'nameNotRecognised',
'decimalLatLongCalculationFromEastingNorthingFailed',
'zeroLatitude',
#'decimalLatLongCalculationFromVerbatimFailed',
'coordinatesCentreOfCountry',
'processingError',
'occCultivatedEscapee',
'coordinatesCentreOfStateProvince',
'decimalLatLongConversionFailed',
'zeroLongitude'))
qa = 'includeall'
this_query$qa <- paste(qa, collapse = ",")
}
if (method == "offline") this_query$email <- email
this_query$reasonTypeId <- download_reason_id
#this_query$sourceTypeId <- ala_sourcetypeid()
this_query$esc <- "\\"
## This guy!
#this_query$sep <- "\t"
this_query$sep <- ","
## Make the file name something intuitive
#this_query$file <- "data"
## Build file name from taxon search and date
fn = gsub("[[:punct:]]", "_", taxon)
fn = paste(fn, Sys.Date(), sep = '_')
fn = gsub(' ', '_', fn)
this_query$file <- fn
## url builder (source utilities_internal.R)
build_url_from_parts <- function(base_url,path=NULL,query=list()) {
this_url <- parse_url(base_url)
this_url$path <- clean_path(this_url$path,path)
if (length(query)>0) {
this_url$query <- query
}
build_url(this_url)
}
## internal url builder function (source utilities_internal.R)
clean_path <- function(...,sep="/") {
path1 <- sapply(list(...),FUN=function(z)paste(z,sep=sep,collapse=sep)) ## collapse individual arguments
## workaround to avoid replacing "http://" with "http:/", since this is now used in GUID strings (July 2016)
path <- paste(path1,sep=sep,collapse=sep) ## paste parts together
path <- gsub("http://","http:@@",path,fixed=TRUE)
path <- gsub(paste0("[",sep,"]+"),sep,path) ## remove multiple slashes
path <- gsub("http:@@","http://",path,fixed=TRUE)
sub(paste0("^",sep),"",path) ## remove leading slash
}
base_url = 'http://biocache.ala.org.au/ws/'
# getOption("ALA4R_server_config")$base_url_biocache
## I think this is all good.
## If I want to simply, remove 'indexed' option
if (method == "indexed"){
this_url <- build_url_from_parts(base_url, c("occurrences", "index", "download"),
query = this_query)
} else {
this_url <- build_url_from_parts(base_url, c("occurrences", "offline", "download"),
query = this_query)
}
if(dry_run) {
return(this_url)
} else {
## Think a lot of this can be junked.
## Build in a pinger to the ALA server.
if (method == "offline") {
## send request
result = GET(this_url)
if(verbose){
if(status_code(result) == 200) {
requestStatus = paste('Request status: ', content(result)$status, sep = '')
queueSize = paste('Queue size: ', content(result)$queueSize, sep = '')
msg = 'ALA query is being processed'
cat(msg, requestStatus, queueSize, sep = '\n')
} else {
msg = paste(': Something has gone wrong with the request ',
'(status ', status_code(result), ')', sep = '')
errorType = content(result)$errorType
cat(errorType, msg, sep = '')
}
}
}
}
}
download_occurrences('genus:Sarcophilus', email = 'chris.ware@csiro.au',
download_reason_id = 7, dry_run = TRUE)
download_occurrences('genus:Sarcophilus', email = 'chris.ware@csiro.au',
download_reason_id = 7, dry_run = FALSE)
detach("package:ALA4R", unload=TRUE)
download_occurrences('genus:Sarcophilus', email = 'chris.ware@csiro.au',
download_reason_id = 7, dry_run = TRUE)
install.packages('RTools')
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
source('//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/utilities.R')
## package libs
library(devtools)
library(roxygen2)
setwd(pkg_root)
getwd()
document()
build()
install()
?gitr.push
?download_occurrences
lib()
library()
?build()
build(source = TRUE)
build(binary = TRUE)
install()
?use_vignette()
use_vignette()
use_vignette('gdmEngine')
library(knitr)
getwd()
setwd(paste(getwd), 'gdmEngine', sep = '/')
setwd(paste(getwd, 'gdmEngine', sep = '/'))
paste(getwd, 'gdmEngine', sep = '/')
setwd(paste(getwd(), 'gdmEngine', sep = '/'))
paste(getwd(), 'gdmEngine', sep = '/')
getwd()
list.files()
setwd(paste(getwd(), 'vignettes' sep = '/'))
setwd(paste(getwd(), 'vignettes', sep = '/'))
knitr()
knit()
list.files()
knit2html(list.files())
?rmarkdown::render
rmarkdown::render(list.files())
gitr.push
gitr.push()
library(assertthat)
gitr.push()
gitr.push('all')
gitr.push(files = 'all')
system.file('gitr.sh')
build()
build()
install()
readRDS(system.file("help", "gitr.sh", package="gdmEngine"))
install()
readRDS(system.file("help", "gitr.bat", package="gdmEngine"))
library(gdmEngine)
readRDS(system.file("help", "gitr.bat", package="gdmEngine"))
?readRDS
system.file("help", "gitr.bat", package="gdmEngine")
system.file("gitr.bat", package="gdmEngine")
?system.file
getwd()
getwd('..')
setwd('..')
getwd()
system.file("gitr.bat", package="gdmEngine")
system.file(package = 'gdmEngine')
system.file('help', 'gitr', package = 'gdmEngine')
system.file('help', 'download_al', package = 'gdmEngine')
system.file('help', 'download_ala', package = 'gdmEngine')
build()
install()
getwd()
build()
install()
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
'Author: Macroecological Modelling Team (CSIRO)',
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution'
)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
build()
install()
build()
install()
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
'Author: Macroecological Modelling Team (CSIRO)',
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution'
)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
## Build with devtools
setwd(pkg_root)
document()
build()
document()
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
setwd(pkg_root)
document()
build()
install()
system.file('help', 'download_ala', package = 'gdmEngine')
build()
install()
system.file('help', 'download_ala', package = 'gdmEngine')
system.file('help', 'gitr', package = 'gdmEngine')
?file.path
file.path('gdmEngine')
file.path(gdmEngine)
.libPaths('gdmEngine')
.libPaths(gdmEngine)
.libPaths
.libPaths()
file.path(paste(.libPaths(), 'gdmEngine', fsep = '/'))
paste(.libPaths(), 'gdmEngine', sep = '/')
file.exists(paste(.libPaths(), 'gdmEngine', sep = '/'))
sh_path = list.files((paste(.libPaths(), 'gdmEngine', sep = '/')), '.sh')
sh_path
sh_path = list.files(paste(.libPaths(), 'gdmEngine', sep = '/')))
sh_path = list.files(paste(.libPaths(), 'gdmEngine', sep = '/'))
sh_path
sh_path = list.files(paste(.libPaths(), 'gdmEngine/exec', sep = '/'))
sh_path
bat_path = list.files(paste(.libPaths(), 'gdmEngine/exec/gitr.bat', sep = '/'))
sh_path = list.files(paste(.libPaths(), 'gdmEngine/exec/gitr.sh', sep = '/'))
assert_that(file.exists(sh_path))
sh_path
sh_path = list.files(paste(.libPaths(), 'gdmEngine/exec/gitr.sh', sep = '/'))
bat_path = list.files(paste(.libPaths(), 'gdmEngine/exec/gitr.bat', sep = '/'))
assert_that(file.exists(sh_path))
assert_that(file.exists(bat_path))
bat_path
sh_path = paste(.libPaths(), 'gdmEngine/exec/gitr.sh', sep = '/')
bat_path = paste(.libPaths(), 'gdmEngine/exec/gitr.bat', sep = '/')
assert_that(file.exists(sh_path))
assert_that(file.exists(bat_path))
build()
install()
rm(list = ls())
rm(list = ls())
gitr.push()
gitr.push
rm(gitr.push)
detach(package:gdmEngine, unload = TRUE)
install()
gitr.push(files = 'all')
library(gdmEngine)
?gitr.push
?gitr.push
?download_occurrences
setwd(pkg_root)
source('//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/utilities.R')
## package libs
library(devtools)
library(roxygen2)
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
'Author: Macroecological Modelling Team (CSIRO)',
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution'
)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
setwd(pkg_root)
document()
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
'Author: Macroecological Modelling Team (CSIRO)',
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution'
)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
## Build with devtools
setwd(pkg_root)
document()
rm(list = ls())
