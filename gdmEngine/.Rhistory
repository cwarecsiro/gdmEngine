"N://source/env/BBANARC/PTS1.flt",
"N://source/env/BBANARC/TXX.flt",
"N://source/env/BBANARC/elev_focalrange_300m_3s_extFill.flt",
"N://source/env/BBANARC/twi_3s_extFill.flt",
"N://source/env/BBANARC/FWOFS.flt")
# turn the stack of rasters into a gigantic matrix
all.env.table <- as.matrix(ENV_Layers)
col.longs<-xFromCol(ENV_Layers)
row.lats<-yFromRow(ENV_Layers)
Cell_Long<-rep(col.longs, times=nrow(ENV_Layers))
Cell_Lat<-rep(row.lats, each=ncol(ENV_Layers), times=1)
#all.env.table<-cbind(Cell_Long, Cell_Lat, all.env.table) ## doesn't work with big vectors
x.all.env.table <- matrix(NA,nrow=nrow(all.env.table),ncol=(ncol(all.env.table)+2))
x.all.env.table[,1] <- Cell_Long
x.all.env.table[,2] <- Cell_Lat
x.all.env.table[,c(3:ncol(x.all.env.table))] <- all.env.table
all.names<-colnames(all.env.table)
colnames(x.all.env.table)<-c("Cell_Long","Cell_Lat",all.names)
# now remove any cells with NAs
y.all.env.table<-x.all.env.table[!is.na(rowSums(x.all.env.table)),]
all.env.table<-as.data.frame(y.all.env.table)
# now make the predictions for the GAM ## TAKES A LONG TIME ##
Predicted.values<-vector(mode="numeric",length=nrow(all.env.table))
blk.size <- 1000000
n.blks <- ceiling(nrow(all.env.table)/blk.size)
for(i.blk in 1:n.blks)
{
blk.start <- (i.blk*blk.size)-blk.size+1
if(i.blk<n.blks)
{
blk.end <- (i.blk*blk.size)
} # end if
else
{
blk.end <- nrow(all.env.table)
} # end else
part.env.table<-all.env.table[c(blk.start:blk.end),]
Predicted.values[c(blk.start:blk.end)] <- predict(Var.mod,
newdata=part.env.table,
type='response')
} # end for i.blk
proc.time() - ptm # Stop the clock
# clamp the predictions at the observed extremes, to avoid stupidity
#Predicted.values[which(Predicted.values > 300)] <- 300
Predicted.values[which(Predicted.values < 0)] <- 0
## Write the predicted values out
first.ras<-raster("N://source/env/BBANARC/PTA.flt")
col.ind<-colFromX(first.ras, all.env.table[,1])
row.ind<-rowFromY(first.ras, all.env.table[,2])
x.y.pred <- cbind(col.ind,row.ind,Predicted.values)
x.y.pred <- x.y.pred[order(row.ind, col.ind),]
x.y.pred <- x.y.pred[complete.cases(x.y.pred),]
write.table(x.y.pred,file="N://processing/Richness/Rich_excl_soil/NSWBBA_long_lat_Predicted_PlantRichness.txt",row.names=FALSE)
#then format these data up as a flt grid using my customised c++ code
# find out how many valid grid cells
nrow(x.y.pred)
ENV_Layers<-stack("N://source/env/BBANARC/onshore_geodetic_Spherical_Cap_Bouguer_2016_extFill.flt",
"N://source/env/BBANARC/EPA.flt",
"N://source/env/BBANARC/PTA.flt",
"N://source/env/BBANARC/PTS1.flt",
"N://source/env/BBANARC/TXX.flt",
"N://source/env/BBANARC/elev_focalrange_300m_3s_extFill.flt",
"N://source/env/BBANARC/twi_3s_extFill.flt",
"N://source/env/BBANARC/FWOFS.flt")
# turn the stack of rasters into a gigantic matrix
all.env.table <- as.matrix(ENV_Layers)
col.longs<-xFromCol(ENV_Layers)
row.lats<-yFromRow(ENV_Layers)
Cell_Long<-rep(col.longs, times=nrow(ENV_Layers))
Cell_Lat<-rep(row.lats, each=ncol(ENV_Layers), times=1)
#all.env.table<-cbind(Cell_Long, Cell_Lat, all.env.table) ## doesn't work with big vectors
x.all.env.table <- matrix(NA,nrow=nrow(all.env.table),ncol=(ncol(all.env.table)+2))
x.all.env.table[,1] <- Cell_Long
x.all.env.table[,2] <- Cell_Lat
x.all.env.table[,c(3:ncol(x.all.env.table))] <- all.env.table
all.names<-colnames(all.env.table)
colnames(x.all.env.table)<-c("Cell_Long","Cell_Lat",all.names)
# now remove any cells with NAs
y.all.env.table<-x.all.env.table[!is.na(rowSums(x.all.env.table)),]
all.env.table<-as.data.frame(y.all.env.table)
# now make the predictions for the GAM ## TAKES A LONG TIME ##
Predicted.values<-vector(mode="numeric",length=nrow(all.env.table))
blk.size <- 1000000
n.blks <- ceiling(nrow(all.env.table)/blk.size)
for(i.blk in 1:n.blks)
{
blk.start <- (i.blk*blk.size)-blk.size+1
if(i.blk<n.blks)
{
blk.end <- (i.blk*blk.size)
} # end if
else
{
blk.end <- nrow(all.env.table)
} # end else
part.env.table<-all.env.table[c(blk.start:blk.end),]
Predicted.values[c(blk.start:blk.end)] <- predict(Var.mod,
newdata=part.env.table,
type='response')
} # end for i.blk
# clamp the predictions at the observed extremes, to avoid stupidity
#Predicted.values[which(Predicted.values > 300)] <- 300
Predicted.values[which(Predicted.values < 0)] <- 0
## Write the predicted values out
first.ras<-raster("N://source/env/BBANARC/PTA.flt")
col.ind<-colFromX(first.ras, all.env.table[,1])
row.ind<-rowFromY(first.ras, all.env.table[,2])
x.y.pred <- cbind(col.ind,row.ind,Predicted.values)
x.y.pred <- x.y.pred[order(row.ind, col.ind),]
x.y.pred <- x.y.pred[complete.cases(x.y.pred),]
write.table(x.y.pred,file="N://processing/Richness/Rich_excl_soil/NSWBBA_long_lat_Predicted_PlantRichness.txt",row.names=FALSE)
#then format these data up as a flt grid using my customised c++ code
# find out how many valid grid cells
nrow(x.y.pred)
saveRDS(Var.mod, file="N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_ExclSoil_ModObject_26Oct17.rds")
saveRDS(Var.mod, file="N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_ExclSoil_ModObject_26Oct17.Rdata")
save(Var.mod, file="N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_ExclSoil_ModObject_26Oct17.Rdata")
## Now all we need to do is project the model
ENV_Layers<-stack("N://source/env/BBANARC/onshore_geodetic_Spherical_Cap_Bouguer_2016_extFill.flt",
"N://source/env/BBANARC/EPA.flt",
"N://source/env/BBANARC/PTA.flt",
"N://source/env/BBANARC/PTS1.flt",
"N://source/env/BBANARC/TXX.flt",
"N://source/env/BBANARC/elev_focalrange_300m_3s_extFill.flt",
"N://source/env/BBANARC/twi_3s_extFill.flt",
"N://source/env/BBANARC/FWOFS.flt")
# turn the stack of rasters into a gigantic matrix
all.env.table <- as.matrix(ENV_Layers)
removeTmpFiles(h=0.005)
load("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_ExclSoil_ModObject_26Oct17.Rdata")
library(raster)
library(mgcv)
library(rgdal)
library(raster)
library(mgcv)
library(rgdal)
# Load functions
source("N://code/Richness/Node_scale_richness_NSW_BBA_26Jun17.R")
source("N://code/GDM/Node_sitepair_sampler_NSW_BBA_28Mar17.R")
# read in the plot environment data
NARClim.plot.env.data <- read.csv("N://processing/biol/Plants_plot/DataPrep/NARClim_plot_env_data_5Oct17.csv")
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
# refine the data to only include sites where the proportion of species that are native is >85%, and removing
# all non-native species
prop.native <- NARClim.plot.env.data$native.spp.richness / (NARClim.plot.env.data$native.spp.richness + NARClim.plot.env.data$alien.spp.richness)
alien.plots<-NARClim.plot.env.data[prop.native<0.85,c(1:3)]
NARClim.plot.env.data <- NARClim.plot.env.data[!(as.character(NARClim.plot.env.data$AEKOS_Site_ID) %in% as.character(alien.plots$AEKOS_Site_ID)),]
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
# refine the data to plots that are above 9 m2 or below 7000 m2
NARClim.plot.env.data<-NARClim.plot.env.data[!(NARClim.plot.env.data$Area_m2<10),]
NARClim.plot.env.data<-NARClim.plot.env.data[!(NARClim.plot.env.data$Area_m2>7000),]
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
## Remove a CORVEG datapoint with very high richness & very low plot size
NARClim.plot.env.data <- NARClim.plot.env.data[!(as.character(NARClim.plot.env.data$AEKOS_Site_ID) == as.character("aekos.org.au/collection/qld.gov.au/corveg/39804")),]
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
## Scale richness to grid cell area & add to the site table
plot.area.rich <- NARClim.plot.env.data[,c(1,4,6)]
scaled.richness <- Scale.Richness.NSW.BBA(plot.area.rich, richness_z = 0.25, region_area = 7300)
NARClim.plot.env.data <- cbind(NARClim.plot.env.data, scaled.richness)
# re-order the columns so scaled richness is not the last col
NARClim.plot.env.data <- cbind(NARClim.plot.env.data[,c(1:7)], NARClim.plot.env.data[,ncol(NARClim.plot.env.data)] , NARClim.plot.env.data[,c(8:(ncol(NARClim.plot.env.data)-1))])
colnames(NARClim.plot.env.data) [8] <- "scaled.richness"
## For the Final Model, fit using all data (no cross-validation), summarise and plot
# Set the number of replicate sets to generate
n_sets <- 10
#establish some catchin tables
var.names<-c("onshore_geodetic_Spherical_Cap_Bouguer_2016_extFill",
"EPA",
"PTA",
"PTS1",
"TXX",
"elev_focalrange_300m_3s_extFill",
"twi_3s_extFill",
"FWOFS")
Fstat.out<-matrix(0,ncol=n_sets,nrow=length(var.names))
row.names(Fstat.out)<-var.names
Pval.out<-matrix(0,ncol=n_sets,nrow=length(var.names))
row.names(Pval.out)<-var.names
Modstat.out<-matrix(0,ncol=n_sets,nrow=2)
row.names(Modstat.out)<-c("Deviance.Explained", "RMSE")
# for plotting
Rep.Out.Data<-matrix(0,nrow=2,ncol=(length(var.names)+1))
colnames(Rep.Out.Data)<-c("scaled.richness",var.names)
test.dat<-matrix(NA,nrow=500,ncol=length(var.names))
colnames(test.dat)<-var.names
Rep.Out.Response <- array(NA,dim=c(500, n_sets, length(var.names)))
# loop over weighted random sample sets of plots
for(i.set in 1:n_sets)
{
## First reduce the number of sites from outside NSW used in the model, by random sample weighted by
# distance to NSW
Dist2NSW.Wt <- decay.curve(x=NARClim.plot.env.data$dist.to.nsw , a=0.05, b=100000, c=2)
# Use these probabilities to randomly select sites
Site.Sample <- rbinom(n=length(Dist2NSW.Wt), size=1, prob=Dist2NSW.Wt)
sample.NARClim.plot.env.data <- NARClim.plot.env.data[Site.Sample>0,]
# - SET THIS
train.plot.env.data <- sample.NARClim.plot.env.data[,c(8,10,52,55,60,72,78,79,80)]
# ----------
# Fit the all variable model
train.plot.env.data <- train.plot.env.data[complete.cases(train.plot.env.data),]
Var.mod<-gam(scaled.richness ~
s(onshore_geodetic_Spherical_Cap_Bouguer_2016_extFill,k=4) +
s(EPA,k=4) +
s(PTA,k=4) +
s(PTS1,k=4) +
s(TXX,k=4) +
s(elev_focalrange_300m_3s_extFill,k=4) +
s(twi_3s_extFill,k=4) +
s(FWOFS,k=4),
family=gaussian(),
data=train.plot.env.data)
out<-summary(Var.mod)
# Predict values for the train data
Pred.dat <- train.plot.env.data
Pred.dat <- Pred.dat[complete.cases(Pred.dat),]
rich.pred<-predict.gam(Var.mod, Pred.dat, type="response", newdata.guaranteed=TRUE)
error = rich.pred - Pred.dat$scaled.richness
Modstat.out[1,i.set] <- out$dev.expl
Modstat.out[2,i.set] <- sqrt(mean(error^2)) # Root Mean Square Error
# catch the output for the predictor variables
Fstat.out[,i.set] <- out$s.table[,3]
Pval.out[,i.set] <- out$s.table[,4]
# for plotting summaries over replicate randomisations
for(i.var in 1:length(var.names))
{test.dat[,i.var]<-mean(train.plot.env.data[,(i.var+1)])}#, na.rm=TRUE)}
for(i.var in 1:length(var.names))
{
this.test.dat<-test.dat
this.gradient<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
# replace the other variables data with their mean values for the part of the gradient being assessed
for(j.var in 1:length(var.names))
{
for(i.grad in 1:500)
{
min.grad<-max((i.grad-100),1)
max.grad<-min((i.grad+100),500)
this.test.dat[i.grad,j.var]<-mean(train.plot.env.data[(train.plot.env.data[,(i.var+1)]>this.gradient[min.grad] & train.plot.env.data[,(i.var+1)]<this.gradient[max.grad]),(j.var+1)])
}#end for i.grad
}# end for j.var
this.test.dat[,(i.var)] <- this.gradient
this.test.dat<-as.data.frame(this.test.dat)
rich.pred<-predict.gam(Var.mod, newdata=this.test.dat, type="response")
Rep.Out.Response[,i.set,i.var] <- rich.pred
}# end for i.var
} # end for i.set
x.axis.names=c("Gravity anomaly",
"Potential evaporation (mm/yr)",
"Mean annual precipitation (mm/yr)",
"Precipitation seasonality",
"Max. temperature warmest month (deg.C)",
"Elevation focal range (300m)",
"Topographic wetness index",
"Coverage by surface water")
mean.rich<-mean(train.plot.env.data$scaled.richness)
response.summary<-matrix(0,500,3)
response.summary<-matrix(NA,nrow=500,ncol=3)
i.var<-1
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=800, height=800)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=1.7 , cex.lab=1.8, xlab=x.axis.names[i.var], ylab="Richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey")
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=800, height=800)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=1.7 , cex.lab=1.8, xlab=x.axis.names[i.var], ylab="Richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey", lwd=1.2)
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=800, height=800)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=1.7 , cex.lab=1.8, xlab=x.axis.names[i.var], ylab="Richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey", lwd=2)
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
for(i.var in 1:length(var.names))
{
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=800, height=800)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=1.7 , cex.lab=1.8, xlab=x.axis.names[i.var], ylab="Richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey", lwd=2)
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
} # end for i.var
for(i.var in 1:length(var.names))
{
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=2000, height=2000)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=2 , cex.lab=2, xlab=x.axis.names[i.var], ylab="Species richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey", lwd=2)
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
} # end for i.var
for(i.var in 1:length(var.names))
{
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=800, height=800)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=2 , cex.lab=2, xlab=x.axis.names[i.var], ylab="Species richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey", lwd=2)
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)◘
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
} # end for i.var
for(i.var in 1:length(var.names))
{
png(paste0("N://processing/Richness/Rich_excl_soil/NSW_BBA_plant_richness_model_plot_var_",i.var,".png"), width=800, height=800)
plot(train.plot.env.data[,(i.var+1)],train.plot.env.data$scaled.richness,col = "blue", cex = .8, cex.axis=2 , cex.lab=2, xlab=x.axis.names[i.var], ylab="Species richness",ylim=c(0,250))
#bw.x <- (max(Rep.Out.Data[,(i.var+1)])-min(Rep.Out.Data[,(i.var+1)]))/50
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, bandwidth=c(bw.x,0.8), nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
#smoothScatter(Rep.Out.Data[,(i.var+1)],Rep.Out.Data$Richness, nrpoints=0, xlab=Var.names[i.var], ylab="Richness",ylim=c(0,40))
this.x<-seq(min(train.plot.env.data[,(i.var+1)],na.rm=TRUE),max(train.plot.env.data[,(i.var+1)],na.rm=TRUE),length.out = nrow(this.test.dat))
lines(rep(mean.rich,times=length(this.x))~this.x,col="dark grey", lwd=2)
for(i.row in 1:500)
{
response.summary[i.row,1] <- mean(Rep.Out.Response[i.row,,i.var])
response.summary[i.row,2] <- quantile(Rep.Out.Response[i.row,,i.var],0.025)
response.summary[i.row,3] <- quantile(Rep.Out.Response[i.row,,i.var],0.975)
}# end for i.row
lines(response.summary[,1]~this.x,col="red",lwd=2)
lines(response.summary[,2]~this.x,col="red",lty=2)
lines(response.summary[,3]~this.x,col="red",lty=2)
dev.off()
} # end for i.var
plot(Var.mod$linear.predictors~Var.mod$fitted.values,lwd=3, xlab="Predicted richness",ylab="Observed richness")
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,lwd=3, xlab="Predicted richness",ylab="Observed richness")
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,col = "blue", cex.lab=2, xlab="Predicted richness",ylab="Observed richness")
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,col = "blue", cex.lab=2, xlab="Predicted richness",ylab="Observed richness")
lines(c(1:100))
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,col = "blue", cex.lab=2, xlab="Predicted richness",ylab="Observed richness")
lines(c(1:107), col="red",lwd=2, lty=2)
png(paste0("N://processing/Richness/Rich_excl_soil/Model_Obs_pred.png"), width=1000,height=1000)
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,col = "blue", cex.lab=2, xlab="Predicted richness",ylab="Observed richness")
lines(c(1:107), col="red",lwd=2, lty=2)
dev.off()
png(paste0("N://processing/Richness/Rich_excl_soil/Model_Obs_pred.png"), width=1000,height=1000)
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,col = "blue", cex.axis=2, cex.lab=2.5, xlab="Predicted richness",ylab="Observed richness")
lines(c(1:107), col="red",lwd=2, lty=2)
dev.off()
png(paste0("N://processing/Richness/Rich_excl_soil/Model_Obs_pred.png"), width=1000,height=1000)
plot(train.plot.env.data$scaled.richness~Var.mod$fitted.values,col = "blue", cex.axis=1.7, cex.lab=2.3, xlab="Predicted richness",ylab="Observed richness")
lines(c(1:107), col="red",lwd=2, lty=2)
dev.off()
library(devtools)
library(roxygen2)
library(Rcpp)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
## write DESCRIPTION file
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
paste('Author:', unname(Sys.info()['user'])),
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution'
#paste('Authors@R:', unname(Sys.info()['user']))
)
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
setwd(pkg_root)
document()
build()
install()
library(gdmEngine)
gitr.push(files = 'all')
library(ALA4R)
library(raster)
library(gdmEngine)
library(data.table)
#library(dplyr)
library(magrittr)
library(plyr)
library(assertthat)
Aus.domain.mask <- raster("//ces-10-cdc/OSM_CDC_GISDATA_work/AUS0025/CLIM/MASK/MASK0.flt")
species.names.file <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/biol/amphibians/AFD-20171211T130458.csv"
species.names <- read.csv(species.names.file)
species.names <- paste(species.names$GENUS, species.names$SPECIES)
species.names <- unique(species.names)
species.records.folder <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/biol/amphibians"
species.records.folder.raw <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/biol/amphibians/raw_files"
data.processing.folder <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/amphibians"
agg.cell.rad <- 2.25
min.rich.limit <- 2
max.rich.limit <- 50
min.rich.rad <- 200
min.rich.proportion <- 0.25
n.pairs.model <- 100000
train.proportion <- 0.8
n.pairs.test <- 20000
Selected.records <- read.csv("//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/amphibians/selected_gridcell_composition_2017-12-14.csv")
Site.Env.Data <- read.csv("//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/amphibians/site_env_data_2018-01-05.csv")
Pairs.Table.Dens <- sitepair_sample_density(site.env.data = Site.Env.Data,
n.pairs.target = n.pairs.model,
domain.mask = Aus.domain.mask,
a.used=0.05,
b.used.factor=2,
c.used=3,
sigma.spair=0.5,
a.spair=0.05,
b.spair.factor=1.0,
c.spair=1)
site.env.data = Site.Env.Data
n.pairs.target = n.pairs.model
domain.mask = Aus.domain.mask
a.used=0.05
b.used.factor=2
c.used=3
sigma.spair=0.5
a.spair=0.05
b.spair.factor=1.0
c.spair=1
n.pairs.total <- ((nrow(site.env.data)^2)-nrow(site.env.data))/2
if(is.null(n.pairs.sample))
{
n.pairs.sample<-floor(n.pairs.target/10)
}# end if is.null(n.pairs.sample)
b.used<-(n.pairs.target/nrow(site.env.data))*b.used.factor
n.pairs.sample=NULL
if(is.null(n.pairs.sample))
{
n.pairs.sample<-floor(n.pairs.target/10)
}# end if is.null(n.pairs.sample)
b.used<-(n.pairs.target/nrow(site.env.data))*b.used.factor
sites.window <- owin(xrange=c(domain.mask@extent@xmin,domain.mask@extent@xmax),yrange=c(domain.mask@extent@ymin,domain.mask@extent@ymax))
library(spatstat)
sites.window <- owin(xrange=c(domain.mask@extent@xmin,domain.mask@extent@xmax),yrange=c(domain.mask@extent@ymin,domain.mask@extent@ymax))
sites.points <- ppp(x=site.env.data$decimalLongitude, y=site.env.data$decimalLatitude, window=sites.window)
sites.density <- density.ppp(site.points, sigma=sigma.spair, at="points", leaveoneout=FALSE, positive=TRUE, verbose=TRUE)
sites.density <- density.ppp(sites.points, sigma=sigma.spair, at="points", leaveoneout=FALSE, positive=TRUE, verbose=TRUE)
sink()
setwd(pkg_root)
document()
build()
install()
Pairs.Table.Dens <- sitepair_sample_density(site.env.data = Site.Env.Data,
n.pairs.target = n.pairs.model,
domain.mask = Aus.domain.mask,
a.used=0.05,
b.used.factor=2,
c.used=3,
sigma.spair=0.5,
a.spair=0.05,
b.spair.factor=1.0,
c.spair=1)
