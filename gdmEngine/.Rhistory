library(devtools)
library(roxygen2)
library(Rcpp)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
install(quick = TRUE)
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
paste('Author:', unname(Sys.info()['user'])),
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution',
'Licence: errr',
#paste('Authors@R:', unname(Sys.info()['user']))
'Imports: Rcpp (>= 0.11.4)',
'LinkingTo: Rcpp'
)
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
## Build with devtools
setwd(pkg_root)
document()
build()
install(quick = TRUE)
library(ALA4R)
library(raster)
library(gdmEngine)
library(data.table)
library(dplyr)
library(magrittr)
# Read in a spatial raster specifying the domain and resolution to be modelled
Aus.domain.mask <- raster("//ces-10-cdc/OSM_CDC_GISDATA_work/AUS0025/CLIM/MASK/MASK0.flt")
# SPECIFY ALA DATA FILTERING THRESHOLDS
data.start.year = 1970
location.uncertainty.limit = 2000
# Specify Environmental layers
climate.files <- list.files(path = "//lw-osm-02-cdc/OSM_CBR_LW_R51141_GPAA_work/ENV/A/OUT/1990", full.names=TRUE, pattern = ".flt")
terrain.files <- list.files(path = "//lw-osm-02-cdc/OSM_CBR_LW_R51141_GPAA_work/ENV/A/OUT/LAND", full.names=TRUE, pattern = ".flt")
soil.files <- list.files(path = "//lw-osm-02-cdc/OSM_CBR_LW_HCAS_work/HCAS2.0/HCAS2.0a/ENV/SOIL/TOP", full.names=TRUE, pattern = ".flt")
env.files <- c(climate.files, terrain.files, soil.files)
env.files <- env.files[(substr(env.files, nchar(env.files)-3, nchar(env.files)) == ".flt")] # to remove some arcmap filenames
env.files <- env.files[-c(26,29,30,32,33,34,37,38,39,40)] # remove grids we don't want to assess in the modelling
env.stk <- stack(env.files, quick=TRUE) #env.stk <- stack(env.files)
species.names.file <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/biol/vascular_plants/APC_and_Orchid_SpeciesNames.csv"
species.names <- read.csv(species.names.file)
species.names <- as.character(species.names[,1])
species.records.folder <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/biol/vascular_plants"
species.records.folder.raw <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/biol/vascular_plants/raw_files"
data.processing.folder <- "//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/vascular_plants"
agg.cell.rad <- 2.25
min.rich.limit <- 10
max.rich.limit <- 400
min.rich.rad <- 200
min.rich.proportion <- 0.25
n.pairs.model <- 100000
train.proportion <- 0.8
n.pairs.test <- 20000
## DOWNLOAD BIOLOGICAL DATA FROM ALA -----------------------------------------------------##
# Download the species records from ALA
download_taxalist(specieslist = species.names,
dst = species.records.folder)
All.records <- merge_downloads(src=species.records.folder.raw,
output.folder = data.processing.folder,
parallel = FALSE)
Filtered.records <- filter_ALA_data(ALA.download.data = All.records$data,
output.folder = data.processing.folder,
domain.mask = Aus.domain.mask,
earliest.year = data.start.year,
spatial.uncertainty.m = location.uncertainty.limit)
Aggregated.records <- aggregate_ALA_data(ALA.filtered.data = Filtered.records,
domain.mask = Aus.domain.mask,
agg.radius.ncells = agg.cell.rad,
output.folder = data.processing.folder)
zz<-Aggregated.records$scientificName
zz<-unique(zz)
zz[c(1:100)]
write.csv(zz,"//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/vascular_plants/SppNames_7Mar18",row.names = FALSE)
Selected.records <- select_gridcells_composition(ALA.aggregated.data = Aggregated.records ,
domain.mask = Aus.domain.mask,
min.richness.threshold = min.rich.limit,
max.richness.threshold = max.rich.limit,
reference.radius.ncells = min.rich.rad,
min.proportion.max.richness = min.rich.proportion,
output.folder = data.processing.folder)
Site.Env.Data <- extract_env_data(ALA.composition.data = Selected.records,
environment.stk = env.stk,
output.folder = data.processing.folder)
climate.files <- list.files(path = "//lw-osm-02-cdc/OSM_CBR_LW_R51141_GPAA_work/ENV/A/OUT/1990", full.names=TRUE, pattern = ".flt")
terrain.files <- list.files(path = "//lw-osm-02-cdc/OSM_CBR_LW_R51141_GPAA_work/ENV/A/OUT/LAND", full.names=TRUE, pattern = ".flt")
#soil.files <- list.files(path = "//lw-osm-02-cdc/OSM_CBR_LW_HCAS_work/HCAS2.0/HCAS2.0a/ENV/SOIL/TOP", full.names=TRUE, pattern = ".flt")
soil.files <- list.files(path = "//osm-23-cdc/OSM_CBR_LW_DEE_work/source/ENV/SOIL/TOP", full.names=TRUE, pattern = ".flt")
env.files <- c(climate.files, terrain.files, soil.files)
env.files <- env.files[(substr(env.files, nchar(env.files)-3, nchar(env.files)) == ".flt")] # to remove some arcmap filenames
env.files <- env.files[-c(26,29,30,32,33,34,37,38,39,40)] # remove grids we don't want to assess in the modelling
env.stk <- stack(env.files, quick=TRUE) #env.stk <- stack(env.files)
es <- env.files[-c(26,29,30,32,33,34,37,38,39,40)] # remove grids we don't want to assess in the modelling
env.stk
Site.Env.Data <- extract_env_data(ALA.composition.data = Selected.records,
environment.stk = env.stk,
output.folder = data.processing.folder)
summary(Site.Env.Data)
ptm <- proc.time()
Final.GDM <- gdm_builder(site.env.data = Site.Env.Data,
composition.data = Selected.records ,
geo=TRUE,
n.pairs.train = n.pairs.model,
n.pairs.test = n.pairs.test,
selection.metric = 'RMSE',
sample.method = 'random',
Indiv.Dev.Explained.Min = 1.0,
n.predictors.min = 10,
output.folder = data.processing.folder,
output.name = "gdm_builder_FinMod")
proc.time() - ptm
summary(Final.GDM$Mean.Final.GDM)
plot(Final.GDM$Mean.Final.GDM)
# correct the predictor data causing gdm to fall over
Site.Env.Data$WDX[which(Site.Env.Data$WDX>800)]<-max(Site.Env.Data$WDX[Site.Env.Data$WDX<800])
## NOW RUN THE SITEPAIR SAMPLING PARAMETER ASSESSMENT ------------------------------------##
# Now create a parameter table listing the possible combinations
parameter.tbl <- expand.grid(p.sample.method=c('random','geodist','envdist','geodens'),
p.selection.metric=c('RMSE'), #add eRMSE?
p.geo=c(TRUE,FALSE),
p.n.predictors.min=c(5,10),
p.Indiv.Dev.Explained.Min=1.0,
p.n.pairs.train=c(100000,200000),
p.n.pairs.test=c(20000,40000),
p.b.used.factor=c(1,2,3),
p.b.dpair.factor=c(1,2,3),
p.b.epair.factor=c(1,2,3),
p.sigma.spair=c(0.25,0.5,1.0),
p.b.spair.factor=c(1,2,3),
stringsAsFactors=FALSE)
# Remove irrelevant parameter combinations
parameter.tbl$p.b.dpair.factor[(parameter.tbl$p.sample.method != 'geodist')]<-NA
parameter.tbl$p.b.epair.factor[(parameter.tbl$p.sample.method != 'envdist')]<-NA
parameter.tbl$p.b.spair.factor[(parameter.tbl$p.sample.method != 'geodens')]<-NA
parameter.tbl$p.sigma.spair[(parameter.tbl$p.sample.method != 'geodens')]<-NA
#parameter.tbl$p.n.predictors.min[(parameter.tbl$p.Indiv.Dev.Explained.Min==1)]<-5
#parameter.tbl$p.n.predictors.min[(parameter.tbl$p.Indiv.Dev.Explained.Min==0.5)]<-10
parameter.tbl$p.n.pairs.train[(parameter.tbl$p.n.pairs.test==40000)]<-200000
parameter.tbl$p.n.pairs.train[(parameter.tbl$p.n.pairs.test==20000)]<-100000
parameter.tbl<-unique(parameter.tbl)
parameter.tbl<-parameter.tbl[order(parameter.tbl$p.sample.method),]
parameter.tbl$run.name<-paste0("Plant_",parameter.tbl$p.sample.method,"_",c(1:nrow(parameter.tbl)))
# Now run all the parameter combinations
analysis.out.folder<-"//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/vascular_plants/SitePairSampleTesting"
write.csv(parameter.tbl,paste0(analysis.out.folder,"/Plant_parameters.csv"),row.names = FALSE)
#                            b.dpair.factor=parameter.tbl$p.b.dpair.factor[i.run],
#                            b.epair.factor=parameter.tbl$p.b.epair.factor[i.run],
#                            sigma.spair=parameter.tbl$p.sigma.spair[i.run],
#                            spair.factor=parameter.tbl$p.b.spair.factor[i.run],
#                           domain.mask=Aus.domain.mask,
#                           output.folder = analysis.out.folder,
#                           output.name = parameter.tbl$run.name[i.run])
#   proc.time() - ptm
#   }# end for i.run
# Or for parallel implementation...
library(foreach)
library(doParallel)
analysis.out.folder
cl<-makeCluster(10) #setup parallel backend to use 10 processors
registerDoParallel(cl)
# run the parallel loop over parameter combinations
foreach(i.run=1:nrow(parameter.tbl), .packages='gdmEngine') %dopar% {
This.GDM <- gdm_builder(site.env.data = Site.Env.Data,
composition.data = Selected.records,
geo=parameter.tbl$p.geo[i.run],
n.pairs.train = parameter.tbl$p.n.pairs.train[i.run],
n.pairs.test = parameter.tbl$p.n.pairs.test[i.run],
correlation.threshold = 0.7,
selection.metric = parameter.tbl$p.selection.metric[i.run],
sample.method=parameter.tbl$p.sample.method[i.run],
Indiv.Dev.Explained.Min = parameter.tbl$p.Indiv.Dev.Explained.Min[i.run],
n.predictors.min = parameter.tbl$p.n.predictors.min[i.run],
b.used.factor=parameter.tbl$p.b.used.factor[i.run],
b.dpair.factor=parameter.tbl$p.b.dpair.factor[i.run],
b.epair.factor=parameter.tbl$p.b.epair.factor[i.run],
sigma.spair=parameter.tbl$p.sigma.spair[i.run],
spair.factor=parameter.tbl$p.b.spair.factor[i.run],
domain.mask=Aus.domain.mask,
output.folder = analysis.out.folder,
output.name = parameter.tbl$run.name[i.run])
} # end for i.run
stopCluster(cl)
library(foreach)
library(doParallel)
cl<-makeCluster(12) #setup parallel backend to use 10 processors
registerDoParallel(cl)
# run the parallel loop over parameter combinations
foreach(i.run=179:nrow(parameter.tbl), .packages='gdmEngine') %dopar% {
This.GDM <- gdm_builder(site.env.data = Site.Env.Data,
composition.data = Selected.records,
geo=parameter.tbl$p.geo[i.run],
n.pairs.train = parameter.tbl$p.n.pairs.train[i.run],
n.pairs.test = parameter.tbl$p.n.pairs.test[i.run],
correlation.threshold = 0.7,
selection.metric = parameter.tbl$p.selection.metric[i.run],
sample.method=parameter.tbl$p.sample.method[i.run],
Indiv.Dev.Explained.Min = parameter.tbl$p.Indiv.Dev.Explained.Min[i.run],
n.predictors.min = parameter.tbl$p.n.predictors.min[i.run],
b.used.factor=parameter.tbl$p.b.used.factor[i.run],
b.dpair.factor=parameter.tbl$p.b.dpair.factor[i.run],
b.epair.factor=parameter.tbl$p.b.epair.factor[i.run],
sigma.spair=parameter.tbl$p.sigma.spair[i.run],
spair.factor=parameter.tbl$p.b.spair.factor[i.run],
domain.mask=Aus.domain.mask,
output.folder = analysis.out.folder,
output.name = parameter.tbl$run.name[i.run])
} # end for i.run
stopCluster(cl)
library(foreach)
library(doParallel)
cl<-makeCluster(12) #setup parallel backend to use 10 processors
registerDoParallel(cl)
# run the parallel loop over parameter combinations
foreach(i.run=353:nrow(parameter.tbl), .packages='gdmEngine') %dopar% {
This.GDM <- gdm_builder(site.env.data = Site.Env.Data,
composition.data = Selected.records,
geo=parameter.tbl$p.geo[i.run],
n.pairs.train = parameter.tbl$p.n.pairs.train[i.run],
n.pairs.test = parameter.tbl$p.n.pairs.test[i.run],
correlation.threshold = 0.7,
selection.metric = parameter.tbl$p.selection.metric[i.run],
sample.method=parameter.tbl$p.sample.method[i.run],
Indiv.Dev.Explained.Min = parameter.tbl$p.Indiv.Dev.Explained.Min[i.run],
n.predictors.min = parameter.tbl$p.n.predictors.min[i.run],
b.used.factor=parameter.tbl$p.b.used.factor[i.run],
b.dpair.factor=parameter.tbl$p.b.dpair.factor[i.run],
b.epair.factor=parameter.tbl$p.b.epair.factor[i.run],
sigma.spair=parameter.tbl$p.sigma.spair[i.run],
spair.factor=parameter.tbl$p.b.spair.factor[i.run],
domain.mask=Aus.domain.mask,
output.folder = analysis.out.folder,
output.name = parameter.tbl$run.name[i.run])
} # end for i.run
stopCluster(cl)
library(devtools)
library(roxygen2)
library(Rcpp)
pkg_root = '//ces-10-cdc/OSM_CDC_MMRG_work/users/bitbucket/gdm_workflow/gdmEngine'
## write DESCRIPTION file
DESCRIPTION = c('Package: gdmEngine',
'Version: 0.01',
paste('Date:', Sys.Date()),
'Title: Workflow for GDM',
'Description: Functions used to develop GDMs',
paste('Author:', unname(Sys.info()['user'])),
'Maintainer: Chris Ware <chris.ware@csiro.au>',
'SystemRequirements: git with shell distribution',
'Licence: errr',
#paste('Authors@R:', unname(Sys.info()['user']))
'Imports: Rcpp (>= 0.11.4)',
'LinkingTo: Rcpp'
)
sink(paste(pkg_root, 'DESCRIPTION', sep = '/'))
cat(DESCRIPTION, sep = '\n')
sink()
## Build with devtools
setwd(pkg_root)
document()
build()
install(quick = TRUE)
library(gdmEngine)
analysis.out.folder<-"//osm-23-cdc/OSM_CBR_LW_DEE_work/processing/biol/vascular_plants/SitePairSampleTesting"
analysis.out.files<-as.character(list.files(analysis.out.folder))
# Read in the parameter table
parameter.tbl <- read.csv(paste0(analysis.out.folder,"/Plant_parameters.csv"))
# Create a table to catch the summary data
results.tbl <- data.frame(ProcTime = as.numeric(rep(NA,times=nrow(parameter.tbl))),
nvars.FinalMod = as.numeric(rep(NA,times=nrow(parameter.tbl))),
n.pairs.used = as.numeric(rep(NA,times=nrow(parameter.tbl))),
D2.FinalMod = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.RMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.eRMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.MAE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
rnd.Mn.RMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
rnd.Mn.eRMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
rnd.Mn.MAE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.Dissimilarity = as.numeric(rep(NA,times=nrow(parameter.tbl))) )
# Now loop through parameter combos, see if there's an output file for each, read it in and
for(i.run in 1:nrow(parameter.tbl))
{
#find if there is an output file to match the run.name
paste(as.character(parameter.tbl$run.name[i.run]),"_",sep='')
f.name <- analysis.out.files[pmatch(paste(as.character(parameter.tbl$run.name[i.run]),"_",sep=''), analysis.out.files)]
if(!is.na(f.name))
{
# open the file
load(file.path(analysis.out.folder,f.name))
# catch the results
results.tbl$ProcTime[i.run] = GDM_Builder_results$ProcessingTime[3]
results.tbl$nvars.FinalMod[i.run] = length(GDM_Builder_results$Predictors)
results.tbl$n.pairs.used[i.run] = length(GDM_Builder_results$Mean.Final.GDM$observed)
results.tbl$D2.FinalMod[i.run] = mean(GDM_Builder_results$Deviance.Explained)
results.tbl$Mn.RMSE[i.run] = mean(GDM_Builder_results$Root.Mean.Squre.Error)
results.tbl$Mn.eRMSE[i.run] = mean(GDM_Builder_results$Equalised.RMSE)
results.tbl$Mn.MAE[i.run] = mean(GDM_Builder_results$Mean.Absolute.Error)
results.tbl$rnd.Mn.RMSE[i.run] = mean(GDM_Builder_results$rnd.Root.Mean.Squre.Error)
results.tbl$rnd.Mn.eRMSE[i.run] = mean(GDM_Builder_results$rnd.Equalised.RMSE)
results.tbl$rnd.Mn.MAE[i.run] = mean(GDM_Builder_results$rnd.Mean.Absolute.Error)
results.tbl$Mn.Dissimilarity[i.run] = mean(GDM_Builder_results$dissimilarity.summary[,4])
# remove the results
rm(GDM_Builder_results)
}# end if !is.na(f.name)
} # end for i.run
parameter.results.tbl <- cbind(parameter.tbl, results.tbl)
analysis.out.folder
write.csv(parameter.results.tbl, paste0(analysis.out.folder,"/Plants_parameters_results.csv"), row.names = FALSE)
missings<-c(354,358,370,374,381)
analysis.out.files<-as.character(list.files(analysis.out.folder))
# Read in the parameter table
parameter.tbl <- read.csv(paste0(analysis.out.folder,"/Plant_parameters.csv"))
# Create a table to catch the summary data
results.tbl <- data.frame(ProcTime = as.numeric(rep(NA,times=nrow(parameter.tbl))),
nvars.FinalMod = as.numeric(rep(NA,times=nrow(parameter.tbl))),
n.pairs.used = as.numeric(rep(NA,times=nrow(parameter.tbl))),
D2.FinalMod = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.RMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.eRMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.MAE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
rnd.Mn.RMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
rnd.Mn.eRMSE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
rnd.Mn.MAE = as.numeric(rep(NA,times=nrow(parameter.tbl))),
Mn.Dissimilarity = as.numeric(rep(NA,times=nrow(parameter.tbl))) )
for(i.run in 1:nrow(parameter.tbl))
{
#find if there is an output file to match the run.name
paste(as.character(parameter.tbl$run.name[i.run]),"_",sep='')
f.name <- analysis.out.files[pmatch(paste(as.character(parameter.tbl$run.name[i.run]),"_",sep=''), analysis.out.files)]
if(!is.na(f.name))
{
# open the file
load(file.path(analysis.out.folder,f.name))
# catch the results
results.tbl$ProcTime[i.run] = GDM_Builder_results$ProcessingTime[3]
results.tbl$nvars.FinalMod[i.run] = length(GDM_Builder_results$Predictors)
results.tbl$n.pairs.used[i.run] = length(GDM_Builder_results$Mean.Final.GDM$observed)
results.tbl$D2.FinalMod[i.run] = mean(GDM_Builder_results$Deviance.Explained)
results.tbl$Mn.RMSE[i.run] = mean(GDM_Builder_results$Root.Mean.Squre.Error)
results.tbl$Mn.eRMSE[i.run] = mean(GDM_Builder_results$Equalised.RMSE)
results.tbl$Mn.MAE[i.run] = mean(GDM_Builder_results$Mean.Absolute.Error)
results.tbl$rnd.Mn.RMSE[i.run] = mean(GDM_Builder_results$rnd.Root.Mean.Squre.Error)
results.tbl$rnd.Mn.eRMSE[i.run] = mean(GDM_Builder_results$rnd.Equalised.RMSE)
results.tbl$rnd.Mn.MAE[i.run] = mean(GDM_Builder_results$rnd.Mean.Absolute.Error)
results.tbl$Mn.Dissimilarity[i.run] = mean(GDM_Builder_results$dissimilarity.summary[,4])
# remove the results
rm(GDM_Builder_results)
}# end if !is.na(f.name)
} # end for i.run
parameter.results.tbl <- cbind(parameter.tbl, results.tbl)
write.csv(parameter.results.tbl, paste0(analysis.out.folder,"/Plants_parameters_results.csv"), row.names = FALSE)
length(missings)
library(foreach)
library(doParallel)
cl<-makeCluster(5)#(12) #setup parallel backend to use 10 processors
registerDoParallel(cl)
# run the parallel loop over parameter combinations
#foreach(i.run=1:nrow(parameter.tbl), .packages='gdmEngine') %dopar% {
foreach(i.run=missings, .packages='gdmEngine') %dopar% {
This.GDM <- gdm_builder(site.env.data = Site.Env.Data,
composition.data = Selected.records,
geo=parameter.tbl$p.geo[i.run],
n.pairs.train = parameter.tbl$p.n.pairs.train[i.run],
n.pairs.test = parameter.tbl$p.n.pairs.test[i.run],
correlation.threshold = 0.7,
selection.metric = parameter.tbl$p.selection.metric[i.run],
sample.method=parameter.tbl$p.sample.method[i.run],
Indiv.Dev.Explained.Min = parameter.tbl$p.Indiv.Dev.Explained.Min[i.run],
n.predictors.min = parameter.tbl$p.n.predictors.min[i.run],
b.used.factor=parameter.tbl$p.b.used.factor[i.run],
b.dpair.factor=parameter.tbl$p.b.dpair.factor[i.run],
b.epair.factor=parameter.tbl$p.b.epair.factor[i.run],
sigma.spair=parameter.tbl$p.sigma.spair[i.run],
spair.factor=parameter.tbl$p.b.spair.factor[i.run],
domain.mask=Aus.domain.mask,
output.folder = analysis.out.folder,
output.name = parameter.tbl$run.name[i.run])
} # end for i.run
stopCluster(cl)
#
